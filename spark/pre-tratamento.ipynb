{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from estados import estados_brasileiros\n",
    "from functools import reduce\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dfTweets = spark.read.csv(\"../twitter/output/tweets_analysis/tweets-analisados-2022-06-06.csv\", header=True,\n",
    "                          inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "dfTweetsTratado = dfTweets.filter(dfTweets.len > 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "path file:/C:/Users/Murilo/Documents/Repositorios/pi-2022/spark/tmp/spark_output/datacsv/tweets already exists.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mdfTweetsTratado\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoalesce\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moption\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mheader\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcsv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./tmp/spark_output/datacsv/tweets\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43memptyValue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\readwriter.py:955\u001B[0m, in \u001B[0;36mDataFrameWriter.csv\u001B[1;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001B[0m\n\u001B[0;32m    947\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode(mode)\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_opts(compression\u001B[38;5;241m=\u001B[39mcompression, sep\u001B[38;5;241m=\u001B[39msep, quote\u001B[38;5;241m=\u001B[39mquote, escape\u001B[38;5;241m=\u001B[39mescape, header\u001B[38;5;241m=\u001B[39mheader,\n\u001B[0;32m    949\u001B[0m                nullValue\u001B[38;5;241m=\u001B[39mnullValue, escapeQuotes\u001B[38;5;241m=\u001B[39mescapeQuotes, quoteAll\u001B[38;5;241m=\u001B[39mquoteAll,\n\u001B[0;32m    950\u001B[0m                dateFormat\u001B[38;5;241m=\u001B[39mdateFormat, timestampFormat\u001B[38;5;241m=\u001B[39mtimestampFormat,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    953\u001B[0m                charToEscapeQuoteEscaping\u001B[38;5;241m=\u001B[39mcharToEscapeQuoteEscaping,\n\u001B[0;32m    954\u001B[0m                encoding\u001B[38;5;241m=\u001B[39mencoding, emptyValue\u001B[38;5;241m=\u001B[39memptyValue, lineSep\u001B[38;5;241m=\u001B[39mlineSep)\n\u001B[1;32m--> 955\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcsv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[0;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[1;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[0;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\utils.py:117\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[1;34m(*a, **kw)\u001B[0m\n\u001B[0;32m    113\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    119\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mAnalysisException\u001B[0m: path file:/C:/Users/Murilo/Documents/Repositorios/pi-2022/spark/tmp/spark_output/datacsv/tweets already exists."
     ]
    }
   ],
   "source": [
    "dfTweetsTratado.coalesce(1).write.option(\"header\", True).csv(\"./tmp/spark_output/datacsv/tweets\", emptyValue='')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "dfEnem = spark.read.option('delimiter', ';').option(\"encoding\", \"ISO-8859-1\").csv(\"./bases/MICRODADOS_ENEM_2019.csv\",\n",
    "                                                                                  header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Criar Sample\n",
    "# dfEnemSample = dfEnem.sample(0.1, seed=69420)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# dfEnemSample.coalesce(1).write.option(\"header\",True).csv(\"./tmp/spark_output/datacsv/enem\", emptyValue='')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "dfEnemEstadosTratados = dfEnem.na.replace(to_replace=estados_brasileiros)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "dfEnemTratado = dfEnemEstadosTratados.selectExpr(\"IN_TREINEIRO as Treineiro\",\n",
    "                                                 \"SG_UF_PROVA as Estado\",\n",
    "                                                 \"TP_PRESENCA_CN as Presenca_CN\",\n",
    "                                                 \"TP_PRESENCA_CH as Presenca_CH\",\n",
    "                                                 \"TP_PRESENCA_LC as Presenca_LC\",\n",
    "                                                 \"TP_PRESENCA_MT as Presenca_MT\",\n",
    "                                                 \"NU_NOTA_CN as Nota_CN\",\n",
    "                                                 \"NU_NOTA_CH as Nota_CH\",\n",
    "                                                 \"NU_NOTA_LC as Nota_LC\",\n",
    "                                                 \"NU_NOTA_MT as Nota_MT\",\n",
    "                                                 \"TP_STATUS_REDACAO as Status_Redacao\",\n",
    "                                                 \"NU_NOTA_REDACAO as Nota_Redacao\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfEnemTratado.coalesce(1).write.option(\"header\", True).csv(\"./tmp/spark_output/datacsv/enem\", emptyValue='')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# dfEnemTratadoSample = dfEnemTratado.sample(0.1, seed=69420)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# dfEnemTratadoSample.coalesce(1).write.option(\"header\", True).csv(\"./tmp/spark_output/datacsv/enem\", emptyValue='')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "dfIDD = spark.read.json(\"./bases/IDD_2019.json\", multiLine=True)\n",
    "dfIDD = dfIDD.fillna(0) # This is the number 0\n",
    "dfIDDEstadosTratados = dfIDD.na.replace(to_replace=estados_brasileiros)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "colunas = dfIDDEstadosTratados.columns\n",
    "novas_colunas = list(map(lambda item: unicodedata.normalize('NFKD', item.replace(\"(\", \"\").replace(\")\", \"\").replace(\"-\",\n",
    "                                                                                                                   \"\").replace(\n",
    "    \" \", \"_\").upper()).encode('ascii', 'ignore').decode('utf-8', 'ignore'), colunas))\n",
    "dfIDDComNovasColunas = reduce(lambda data, idx: data.withColumnRenamed(colunas[idx], novas_colunas[idx]),\n",
    "                              range(len(colunas)), dfIDDEstadosTratados)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "dfIDDTratado = dfIDDComNovasColunas.selectExpr(\"IDD_CONTINUO as IDD_Continuo\",\n",
    "                                                           \"IDD_FAIXA as IDD_Faixa\",\n",
    "                                                           \"NOTA_BRUTA__IDD as Nota_Bruta_IDD\",\n",
    "                                                           \"SIGLA_DA_UF as Estado_Curso\",\n",
    "                                                           \"NOME_DA_IES as Instituicao_Ensino\",\n",
    "                                                           \"No_DE_CONCLUINTES_INSCRITOS as Concluintes_Inscritos\",\n",
    "                                                           \"No_DE_CONCLUINTES_PARTICIPANTES as Concluintes_Participantes\",\n",
    "                                                           \"No_DE_CONCLUINTES_PARTICIPANTES_COM_NOTA_NO_ENEM as Concluintes_Participantes_Nota_Enem\",\n",
    "                                                           \"PROPORCAO_DE_CONCLUINTES_PARTICIPANTES_COM_NOTA_NO_ENEM as Prop_Concluintes_Participantes_Nota_Enem_IDD\",\n",
    "                                                           \"AREA_DE_AVALIACAO as Curso\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "dfIDDTratado.coalesce(1).write.option(\"header\", True).csv(\"./tmp/spark_output/datacsv/idd\", emptyValue='')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}